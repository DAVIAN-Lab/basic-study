| | | | | | | | | |
|-|-|-|-|-|-|-|-|-|
| |Order|Theme|Date|Presenter|Lecture|Practice|T.A.|Reading Materials|
| |1|Linear Algebra, Probabilities, ML| | |CS 229 lec 1 - Introduction and Logistics, Review of Linear Algebra|  Practice1,2  | | |
| |2|Linear Algebra, Probabilities, ML| | |CS 229 lec 2 - Review of Matrix Calculus, Review of Probability|Practice3,4| | |
| |3|Linear Algebra, Probabilities, ML| | |CS 229 lec 3 - Review of Probability and Statistics, Setting of Supervised Learning|Practice5,6| | |
| |4|Linear Algebra, Probabilities, ML| | |CS 229 lec 4 - Linear Regression (Normal Equations, probabilistic interpretation), MLE |Practice7| | |
| |5|Linear Algebra, Probabilities, ML| | |CS 229 lec 5 - Perceptron, Logistic Regression, Newton's Method|X| | |
| |6|Linear Algebra, Probabilities, ML| | |CS 229 lec 21 - Evaluation Metrics (F1, ROC, etc..)| | | |
| |7|Deep Learning| | |lec 1-2 (Introduction, ML basics 1) Discussion 1| | | |
| |8|Deep Learning| | |lec 3-4 (ML basics 2, optimization) Discussion 2|hw1| |https://distill.pub/2017/momentum/ https://openai.com/blog/deep-double-descent/ https://mml-book.github.io/book/mml-book.pdf (p.291-p.303)|
| |9|Deep Learning| | |lec 5-6 (Backpropogation, CNN) Discussion 3| | | |
| |10|Deep Learning| | |lec 7-8(Getting neural nets to train, Computer Vision) Discussion 4|X| |overfitting in deep neural network ( https://lilianweng.github.io/lil-log/2019/03/14/are-deep-neural-networks-dramatically-overfitted.html )|
| |11|Deep Learning| | |lec 9 Generating images from CNN, lec 10 RNN Discussion 5| | |RNN and Regularization(Dropout):  https://medium.com/curg/deep-rnn-%EC%A0%95%EA%B7%9C%ED%99%94%EA%B0%80-%EA%B6%81%EA%B8%88%ED%95%B4-7d69f3bbc171   Bidirenctional RNN: https://d2l.ai/chapter_recurrent-modern/bi-rnn.html    Seq to Seq Machine Translation: https://deep-learning-study.tistory.com/685   Beam Search: https://littlefoxdiary.tistory.com/4|
| |12|Deep Learning| | |lec11 Seq2Seq Discussion 6| | | |
| |13|Deep Learning| | |lec 12 Transformers  Discussion 7|hw3| |Transformer: https://nlp.seas.harvard.edu/2018/04/03/attention.html#model-architecture |
| |14|Deep Learning| | |lec 13 NLP applications Discussion 8 (pretraining)| | | |
| |15|Deep Learning| | |lec 14-15 (Imitation learning, policy gradient) Discussion 8 (imitation learning), discussion 9 (policy graident)| | | |
| |16|Deep Learning| | |Information Theory 1~3 (Entropy, Cross-Entropy, KL Divergence) https://www.youtube.com/watch?v=KRNz-JhWXC8&list=PLKs7xpqpX1bcQAHSjlZAv8vHftDj6kXrn   |hw2| | |
| |17|Deep Learning| | |lec 17 (Autoencoder & Latent variable model) Discussion 10| | | |
| |18|Deep Learning| | |lec 18 (VAE)| | | |
| |19|Deep Learning| | |lec 19 (GAN) Discussion 11| | | |
| |20|Deep Learning| | |Deep Learning EXAM| | | |
